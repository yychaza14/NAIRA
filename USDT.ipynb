{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mJSgF40Nv3sjFewKW-Rppc4045dB9Ow6",
      "authorship_tag": "ABX9TyNrrRedn24hMyDN2o+dwzv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yychaza14/NAIRA/blob/main/USDT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "class BinanceP2PAPI:\n",
        "    BASE_URL = \"https://p2p.binance.com/bapi/c2c/v2/friendly/c2c/adv/search\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'Accept': '*/*',\n",
        "            'Accept-Language': 'en-US,en;q=0.9',\n",
        "            'Content-Type': 'application/json',\n",
        "            'Origin': 'https://p2p.binance.com',\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        })\n",
        "\n",
        "    def search_advertisements(self,\n",
        "                            asset: str = \"USDT\",\n",
        "                            fiat: str = \"XAF\",\n",
        "                            trade_type: str = \"BUY\",\n",
        "                            payment_method: str = None,\n",
        "                            page: int = 1,\n",
        "                            rows: int = 10):\n",
        "          \"\"\"\n",
        "          Search P2P advertisements on Binance and return raw JSON response\n",
        "          \"\"\"\n",
        "          payload = {\n",
        "              \"asset\": asset,\n",
        "              \"fiat\": fiat,\n",
        "              \"merchantCheck\": True,\n",
        "              \"page\": page,\n",
        "              \"payTypes\": [payment_method] if payment_method else [],\n",
        "              \"publisherType\": None,\n",
        "              \"rows\": rows,\n",
        "              \"tradeType\": trade_type\n",
        "          }\n",
        "\n",
        "          try:\n",
        "              response = self.session.post(self.BASE_URL, json=payload)\n",
        "              response.raise_for_status()\n",
        "              return response.json()\n",
        "\n",
        "          except requests.exceptions.RequestException as e:\n",
        "              return {\n",
        "                  \"success\": False,\n",
        "                  \"code\": \"request_failed\",\n",
        "                  \"message\": str(e),\n",
        "                  \"data\": None\n",
        "              }\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    api = BinanceP2PAPI()\n",
        "\n",
        "    response = api.search_advertisements(\n",
        "        asset=\"USDT\",\n",
        "        fiat=\"XAF\",\n",
        "        trade_type=\"BUY\",\n",
        "        rows=1\n",
        "    )\n",
        "    # ... (rest of your code)\n",
        "\n",
        "    if response[\"success\"]:\n",
        "        data = []\n",
        "        for ad in response[\"data\"]:\n",
        "            price = ad[\"adv\"][\"price\"]\n",
        "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            data.append([current_time, price])\n",
        "\n",
        "        df = pd.DataFrame(data, columns=[\"Timestamp\", \"Price\"])\n",
        "        df.to_excel(\"binance_p2p_data.xlsx\", index=False)\n",
        "        print(\"Data saved to Excel file.\")\n",
        "    else:\n",
        "        print(\"Error:\", response[\"message\"])\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QBkJM2uIrbpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf39845-7cfb-4c5f-c776-665dee1e24ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to Excel file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!pip install selenium schedule\n",
        "!pip install schedule\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin'''\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import re\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "class BybitScraper:\n",
        "    def __init__(self, headless: bool = True, timeout: int = 30):\n",
        "        \"\"\"Initialize the Bybit P2P scraper.\"\"\"\n",
        "        self.timeout = timeout\n",
        "        self._setup_logging()\n",
        "        self.driver = self._initialize_driver(headless)\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            datefmt='%Y-%m-%d %H:%M:%S'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _initialize_driver(self, headless: bool) -> webdriver.Chrome:\n",
        "        \"\"\"Initialize and configure the Chrome WebDriver\"\"\"\n",
        "        chrome_options = Options()\n",
        "        if headless:\n",
        "            chrome_options.add_argument('--headless')\n",
        "\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        chrome_options.add_argument('--window-size=1920,1080')\n",
        "        chrome_options.add_argument('--disable-gpu')\n",
        "        chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
        "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "        chrome_options.add_experimental_option('useAutomationExtension', False)\n",
        "        chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                                  \"Chrome/120.0.0.0 Safari/537.36\")\n",
        "\n",
        "        return webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    def _clean_price(self, price_text: str) -> Optional[float]:\n",
        "        \"\"\"\n",
        "        Clean and convert price text to float.\n",
        "        Returns None if the price is invalid.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not price_text or price_text.isspace():\n",
        "                return None\n",
        "\n",
        "            # Remove currency symbol and any non-numeric characters except decimal point\n",
        "            price_str = re.sub(r'[^\\d.]', '', price_text.split('\\n')[0])\n",
        "            return float(price_str) if price_str else None\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error cleaning price {price_text}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_p2p_listings(\n",
        "        self,\n",
        "        token: str = \"USDT\",\n",
        "        fiat: str = \"NGN\",\n",
        "        action_type: str = \"1\",\n",
        "        max_retries: int = 10\n",
        "    ) -> Dict[str, Union[bool, List[Dict], str]]:\n",
        "        \"\"\"Scrape P2P listings from Bybit website.\"\"\"\n",
        "        url = f\"https://www.bybit.com/fiat/trade/otc?actionType={action_type}&token={token}&fiat={fiat}\"\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                self.logger.info(f\"Attempt {attempt + 1}/{max_retries}: Loading {url}\")\n",
        "                self.driver.get(url)\n",
        "\n",
        "                # Wait for the main content to load\n",
        "                WebDriverWait(self.driver, self.timeout).until(\n",
        "                    EC.presence_of_element_located((By.TAG_NAME, \"tbody\"))\n",
        "                )\n",
        "\n",
        "                # Additional wait for dynamic content\n",
        "                time.sleep(5)\n",
        "\n",
        "                # Take screenshot for debugging\n",
        "                screenshot_path = \"bybit_page.png\"\n",
        "                self.driver.save_screenshot(screenshot_path)\n",
        "                self.logger.info(f\"Screenshot saved as '{screenshot_path}'\")\n",
        "\n",
        "                # Extract prices from the table\n",
        "                prices = []\n",
        "                rows = self.driver.find_elements(By.CSS_SELECTOR, \"tbody tr\")\n",
        "\n",
        "                for row in rows:\n",
        "                    try:\n",
        "                        # Get the price cell\n",
        "                        price_element = row.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\")\n",
        "                        price_text = price_element.text.strip()\n",
        "\n",
        "                        # Clean and validate the price\n",
        "                        cleaned_price = self._clean_price(price_text)\n",
        "                        if cleaned_price is not None:\n",
        "                            prices.append({\n",
        "                                'price': cleaned_price,\n",
        "                            })\n",
        "                    except NoSuchElementException:\n",
        "                        continue\n",
        "                    except Exception as e:\n",
        "                        self.logger.warning(f\"Error parsing row: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "                # Filter out empty prices and sort by price\n",
        "                valid_prices = [p for p in prices if p['price'] is not None]\n",
        "                valid_prices.sort(key=lambda x: x['price'])\n",
        "\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"data\": valid_prices,\n",
        "                    \"metadata\": {\n",
        "                        \"token\": token,\n",
        "                        \"fiat\": fiat,\n",
        "                        \"action_type\": \"buy\" if action_type == \"1\" else \"sell\",\n",
        "                        \"timestamp\": datetime.now().isoformat(),\n",
        "                        \"total_rows_found\": len(rows),\n",
        "                        \"valid_prices_found\": len(valid_prices)\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            except TimeoutException:\n",
        "                self.logger.error(f\"Timeout waiting for content on attempt {attempt + 1}\")\n",
        "                if attempt == max_retries - 1:\n",
        "                    return {\n",
        "                        \"success\": False,\n",
        "                        \"data\": None,\n",
        "                        \"message\": \"Timeout error: Page failed to load after multiple attempts\"\n",
        "                    }\n",
        "                time.sleep(5)\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Unexpected error: {str(e)}\")\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"data\": None,\n",
        "                    \"message\": f\"Error: {str(e)}\"\n",
        "                }\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Clean up resources\"\"\"\n",
        "        if self.driver:\n",
        "            self.driver.quit()\n",
        "            self.logger.info(\"Browser session closed\")\n",
        "\n",
        "def main():\n",
        "    scraper = BybitScraper(headless=True)\n",
        "\n",
        "    try:\n",
        "        result = scraper.get_p2p_listings(\n",
        "            token=\"USDT\",\n",
        "            fiat=\"NGN\",\n",
        "            action_type=\"1\"\n",
        "        )\n",
        "        if result[\"success\"]:\n",
        "          data = []\n",
        "          for ad in result[\"data\"]:\n",
        "            price = ad[\"price\"]\n",
        "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            data.append([current_time, price])\n",
        "          df = pd.DataFrame(data, columns=[\"Timestamp\", \"Price\"])\n",
        "          df.to_excel(\"bybit.xlsx\", index=False)\n",
        "          print(\"Data saved to Excel file.\")\n",
        "          print(json.dumps(data, indent=2))\n",
        "        else:\n",
        "          print(\"Error:\", result[\"message\"])\n",
        "        #print(json.dumps(result, indent=2))\n",
        "\n",
        "    finally:\n",
        "        scraper.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj6q_LomMSfK",
        "outputId": "1f3f47d7-3b29-42a3-9841-0c41e0b59c90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to Excel file.\n",
            "[\n",
            "  [\n",
            "    \"2024-11-14 20:55:55\",\n",
            "    1736.0\n",
            "  ],\n",
            "  [\n",
            "    \"2024-11-14 20:55:55\",\n",
            "    1736.0\n",
            "  ],\n",
            "  [\n",
            "    \"2024-11-14 20:55:55\",\n",
            "    1736.0\n",
            "  ],\n",
            "  [\n",
            "    \"2024-11-14 20:55:55\",\n",
            "    1745.0\n",
            "  ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHV7vW1Fi8JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import re\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "class BybitScraper:\n",
        "    def __init__(self, headless: bool = True, timeout: int = 30):\n",
        "        \"\"\"Initialize the Bybit P2P scraper.\"\"\"\n",
        "        self.timeout = timeout\n",
        "        self._setup_logging()\n",
        "        self.driver = self._initialize_driver(headless)\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        \"\"\"Set up logging configuration.\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            datefmt='%Y-%m-%d %H:%M:%S',\n",
        "            handlers=[\n",
        "                logging.FileHandler('bybit_scraper.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _initialize_driver(self, headless: bool) -> webdriver.Chrome:\n",
        "        \"\"\"Initialize and configure the Chrome WebDriver.\"\"\"\n",
        "        chrome_options = Options()\n",
        "        if headless:\n",
        "            chrome_options.add_argument('--headless=new')  # Updated for newer Chrome versions\n",
        "\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        chrome_options.add_argument('--window-size=1920,1080')\n",
        "        chrome_options.add_argument('--disable-gpu')\n",
        "        chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
        "        chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "        chrome_options.add_experimental_option('useAutomationExtension', False)\n",
        "        chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                                  \"Chrome/120.0.0.0 Safari/537.36\")\n",
        "\n",
        "        service = Service()  # Let Selenium handle driver path\n",
        "        return webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "    def _clean_price(self, price_text: str) -> Optional[float]:\n",
        "        \"\"\"\n",
        "        Clean and convert price text to float.\n",
        "        Returns None if the price is invalid.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not price_text or price_text.isspace():\n",
        "                return None\n",
        "\n",
        "            # Remove currency symbol and any non-numeric characters except decimal point\n",
        "            price_str = re.sub(r'[^\\d.]', '', price_text.split('\\n')[0])\n",
        "            return float(price_str) if price_str else None\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error cleaning price {price_text}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _extract_additional_info(self, row) -> Dict:\n",
        "        \"\"\"Extract additional information from the row.\"\"\"\n",
        "        try:\n",
        "            available_amount = row.find_element(By.CSS_SELECTOR, \"td:nth-child(3)\").text.strip()\n",
        "            payment_methods = row.find_element(By.CSS_SELECTOR, \"td:nth-child(4)\").text.strip()\n",
        "            merchant_name = row.find_element(By.CSS_SELECTOR, \"td:nth-child(5)\").text.strip()\n",
        "\n",
        "            return {\n",
        "                \"available_amount\": available_amount,\n",
        "                \"payment_methods\": payment_methods,\n",
        "                \"merchant_name\": merchant_name\n",
        "            }\n",
        "        except NoSuchElementException as e:\n",
        "            self.logger.warning(f\"Could not extract additional info: {str(e)}\")\n",
        "            return {}\n",
        "\n",
        "    def get_p2p_listings(\n",
        "        self,\n",
        "        token: str = \"USDT\",\n",
        "        fiat: str = \"NGN\",\n",
        "        action_type: str = \"1\",\n",
        "        max_retries: int = 10\n",
        "    ) -> Dict[str, Union[bool, List[Dict], str]]:\n",
        "        \"\"\"Scrape P2P listings from Bybit website.\"\"\"\n",
        "        url = f\"https://www.bybit.com/fiat/trade/otc?actionType={action_type}&token={token}&fiat={fiat}\"\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                self.logger.info(f\"Attempt {attempt + 1}/{max_retries}: Loading {url}\")\n",
        "                self.driver.get(url)\n",
        "\n",
        "                # Wait for the main content to load\n",
        "                WebDriverWait(self.driver, self.timeout).until(\n",
        "                    EC.presence_of_element_located((By.TAG_NAME, \"tbody\"))\n",
        "                )\n",
        "\n",
        "                # Additional wait for dynamic content\n",
        "                time.sleep(5)\n",
        "\n",
        "                # Take screenshot for debugging\n",
        "                screenshot_path = f\"bybit_page_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "                self.driver.save_screenshot(screenshot_path)\n",
        "                self.logger.info(f\"Screenshot saved as '{screenshot_path}'\")\n",
        "\n",
        "                # Extract data from the table\n",
        "                listings = []\n",
        "                rows = self.driver.find_elements(By.CSS_SELECTOR, \"tbody tr\")\n",
        "\n",
        "                for row in rows:\n",
        "                    try:\n",
        "                        # Get the price cell\n",
        "                        price_element = row.find_element(By.CSS_SELECTOR, \"td:nth-child(2)\")\n",
        "                        price_text = price_element.text.strip()\n",
        "\n",
        "                        # Clean and validate the price\n",
        "                        cleaned_price = self._clean_price(price_text)\n",
        "                        if cleaned_price is not None:\n",
        "                            listing_data = {\n",
        "                                'price': cleaned_price,\n",
        "                                'timestamp': datetime.now().isoformat(),\n",
        "                                **self._extract_additional_info(row)\n",
        "                            }\n",
        "                            listings.append(listing_data)\n",
        "                    except NoSuchElementException:\n",
        "                        continue\n",
        "                    except Exception as e:\n",
        "                        self.logger.warning(f\"Error parsing row: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "                # Filter out empty prices and sort by price\n",
        "                valid_listings = [l for l in listings if l['price'] is not None]\n",
        "                valid_listings.sort(key=lambda x: x['price'])\n",
        "\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"data\": valid_listings,\n",
        "                    \"metadata\": {\n",
        "                        \"token\": token,\n",
        "                        \"fiat\": fiat,\n",
        "                        \"action_type\": \"buy\" if action_type == \"1\" else \"sell\",\n",
        "                        \"timestamp\": datetime.now().isoformat(),\n",
        "                        \"total_rows_found\": len(rows),\n",
        "                        \"valid_listings_found\": len(valid_listings)\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            except TimeoutException:\n",
        "                self.logger.error(f\"Timeout waiting for content on attempt {attempt + 1}\")\n",
        "                if attempt == max_retries - 1:\n",
        "                    return {\n",
        "                        \"success\": False,\n",
        "                        \"data\": None,\n",
        "                        \"message\": \"Timeout error: Page failed to load after multiple attempts\"\n",
        "                    }\n",
        "                time.sleep(5)\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Unexpected error: {str(e)}\")\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"data\": None,\n",
        "                    \"message\": f\"Error: {str(e)}\"\n",
        "                }\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Clean up resources.\"\"\"\n",
        "        if self.driver:\n",
        "            self.driver.quit()\n",
        "            self.logger.info(\"Browser session closed\")\n",
        "\n",
        "def save_to_excel(data: List[Dict], filename: str = \"bybit_data.xlsx\"):\n",
        "    \"\"\"Save the scraped data to an Excel file.\"\"\"\n",
        "    try:\n",
        "        df = pd.DataFrame(data)\n",
        "        df.to_excel(filename, index=False)\n",
        "        print(f\"Data successfully saved to {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to Excel: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    scraper = BybitScraper(headless=True)\n",
        "\n",
        "    try:\n",
        "        result = scraper.get_p2p_listings(\n",
        "            token=\"USDT\",\n",
        "            fiat=\"NGN\",\n",
        "            action_type=\"1\"\n",
        "        )\n",
        "\n",
        "        if result[\"success\"]:\n",
        "            # Save raw data to JSON for backup\n",
        "            with open(\"bybit_raw_data.json\", \"w\") as f:\n",
        "                json.dump(result, f, indent=2)\n",
        "\n",
        "            # Save processed data to Excel\n",
        "            save_to_excel(result[\"data\"])\n",
        "\n",
        "            # Print summary\n",
        "            print(f\"Time of scraping: {result['metadata']['timestamp']}\")\n",
        "\n",
        "            if result[\"data\"]:\n",
        "                print(f\"\\nPrice Range:\")\n",
        "                print(f\"Lowest price: {result['data'][0]['price']} {result['metadata']['fiat']}\")\n",
        "                print(f\"Highest price: {result['data'][-1]['price']} {result['metadata']['fiat']}\")\n",
        "        else:\n",
        "            print(\"Error:\", result[\"message\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "    finally:\n",
        "        scraper.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lcPDQ42yZQo_",
        "outputId": "4144f4cb-038f-4dcd-ca36-9cd2416af50d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to bybit_data.xlsx\n",
            "\n",
            "Scraping Summary:\n",
            "Total listings found: 11\n",
            "Valid listings processed: 4\n",
            "Time of scraping: 2024-11-14T20:40:38.606036\n",
            "\n",
            "Price Range:\n",
            "Lowest price: 1736.0 NGN\n",
            "Highest price: 1749.95 NGN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import logging\n",
        "import re\n",
        "from typing import Dict, List, Optional, Union\n",
        "import gspread\n",
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "import os\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "class GoogleSheetsManager:\n",
        "    def __init__(self, credentials_json: str, spreadsheet_id: str):\n",
        "        \"\"\"Initialize Google Sheets connection.\"\"\"\n",
        "        self.scope = [\n",
        "            'https://www.googleapis.com/auth/spreadsheets',\n",
        "            'https://www.googleapis.com/auth/drive'\n",
        "        ]\n",
        "\n",
        "        # Load credentials from environment variable or file\n",
        "        if os.path.exists(credentials_json):\n",
        "            self.credentials = Credentials.from_service_account_file(\n",
        "                credentials_json,\n",
        "                scopes=self.scope\n",
        "            )\n",
        "        else:\n",
        "            # For GitHub Actions, load from environment variable\n",
        "            import json\n",
        "            creds_dict = json.loads(credentials_json)\n",
        "            self.credentials = Credentials.from_service_account_info(\n",
        "                creds_dict,\n",
        "                scopes=self.scope\n",
        "            )\n",
        "\n",
        "        self.client = gspread.authorize(self.credentials)\n",
        "        self.spreadsheet_id = spreadsheet_id\n",
        "        self.sheet = self.client.open_by_key(spreadsheet_id).sheet1\n",
        "\n",
        "    def append_data(self, data: List[Dict]) -> None:\n",
        "        \"\"\"Append new data to the Google Sheet.\"\"\"\n",
        "        if not data:\n",
        "            return\n",
        "\n",
        "        # Prepare headers if sheet is empty\n",
        "        headers = list(data[0].keys())\n",
        "        if self.sheet.row_count == 0:\n",
        "            self.sheet.append_row(headers)\n",
        "\n",
        "        # Convert data to rows\n",
        "        rows = []\n",
        "        for item in data:\n",
        "            row = [str(item.get(header, '')) for header in headers]\n",
        "            rows.append(row)\n",
        "\n",
        "        # Append all rows at once\n",
        "        self.sheet.append_rows(rows)\n",
        "\n",
        "class BybitScraper:\n",
        "    # ... (previous BybitScraper code remains the same until the get_p2p_listings method)\n",
        "\n",
        "    def get_p2p_listings(\n",
        "        self,\n",
        "        token: str = \"USDT\",\n",
        "        fiat: str = \"NGN\",\n",
        "        action_type: str = \"1\",\n",
        "        max_retries: int = 10\n",
        "    ) -> Dict[str, Union[bool, List[Dict], str]]:\n",
        "        \"\"\"Scrape P2P listings from Bybit website.\"\"\"\n",
        "        url = f\"https://www.bybit.com/fiat/trade/otc?actionType={action_type}&token={token}&fiat={fiat}\"\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                self.logger.info(f\"Attempt {attempt + 1}/{max_retries}: Loading {url}\")\n",
        "                self.driver.get(url)\n",
        "\n",
        "                # ... (previous code remains the same)\n",
        "\n",
        "                # Update timestamp to include timezone\n",
        "                current_time = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "                # Filter out empty prices and sort by price\n",
        "                valid_listings = [l for l in listings if l['price'] is not None]\n",
        "                valid_listings.sort(key=lambda x: x['price'])\n",
        "\n",
        "                # Add run_id to track separate scraping runs\n",
        "                run_id = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')\n",
        "                for listing in valid_listings:\n",
        "                    listing['run_id'] = run_id\n",
        "\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"data\": valid_listings,\n",
        "                    \"metadata\": {\n",
        "                        \"token\": token,\n",
        "                        \"fiat\": fiat,\n",
        "                        \"action_type\": \"buy\" if action_type == \"1\" else \"sell\",\n",
        "                        \"timestamp\": current_time,\n",
        "                        \"total_rows_found\": len(rows),\n",
        "                        \"valid_listings_found\": len(valid_listings),\n",
        "                        \"run_id\": run_id\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                # ... (rest of the method remains the same)\n",
        "\n",
        "def main():\n",
        "    # Get configuration from environment variables\n",
        "    GOOGLE_SHEETS_CREDS = os.getenv('GOOGLE_SHEETS_CREDS')\n",
        "    SPREADSHEET_ID = os.getenv('SPREADSHEET_ID')\n",
        "\n",
        "    if not GOOGLE_SHEETS_CREDS or not SPREADSHEET_ID:\n",
        "        raise ValueError(\"Missing required environment variables for Google Sheets integration\")\n",
        "\n",
        "    scraper = BybitScraper(headless=True)\n",
        "    sheets_manager = GoogleSheetsManager(GOOGLE_SHEETS_CREDS, SPREADSHEET_ID)\n",
        "\n",
        "    try:\n",
        "        result = scraper.get_p2p_listings(\n",
        "            token=\"USDT\",\n",
        "            fiat=\"NGN\",\n",
        "            action_type=\"1\"\n",
        "        )\n",
        "\n",
        "        if result[\"success\"]:\n",
        "            # Append data to Google Sheets\n",
        "            sheets_manager.append_data(result[\"data\"])\n",
        "\n",
        "            # Print summary\n",
        "            print(\"\\nScraping Summary:\")\n",
        "            print(f\"Total listings found: {result['metadata']['total_rows_found']}\")\n",
        "            print(f\"Valid listings processed: {result['metadata']['valid_listings_found']}\")\n",
        "            print(f\"Time of scraping: {result['metadata']['timestamp']}\")\n",
        "            print(f\"Run ID: {result['metadata']['run_id']}\")\n",
        "\n",
        "            if result[\"data\"]:\n",
        "                print(f\"\\nPrice Range:\")\n",
        "                print(f\"Lowest price: {result['data'][0]['price']} {result['metadata']['fiat']}\")\n",
        "                print(f\"Highest price: {result['data'][-1]['price']} {result['metadata']['fiat']}\")\n",
        "        else:\n",
        "            print(\"Error:\", result[\"message\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "    finally:\n",
        "        scraper.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "collapsed": true,
        "id": "iy_kDRPPjUII",
        "outputId": "3a4959d1-4aff-47ed-9a19-5c0533b4c8bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected 'except' or 'finally' block (<ipython-input-8-7fbf8f118f67>, line 115)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-7fbf8f118f67>\"\u001b[0;36m, line \u001b[0;32m115\u001b[0m\n\u001b[0;31m    def main():\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected 'except' or 'finally' block\n"
          ]
        }
      ]
    }
  ]
}